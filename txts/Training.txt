#!/usr/bin/env python
# coding: utf-8
"""
========================================================================
Â© 2021 Institute for Clinical Evaluative Sciences. All rights reserved.

TERMS OF USE:
##Not for distribution.## This code and data is provided to the user solely for its own non-commercial use by individuals and/or not-for-profit corporations. User shall not distribute without express written permission from the Institute for Clinical Evaluative Sciences.

##Not-for-profit.## This code and data may not be used in connection with profit generating activities.

##No liability.## The Institute for Clinical Evaluative Sciences makes no warranty or representation regarding the fitness, quality or reliability of this code and data.

##No Support.## The Institute for Clinical Evaluative Sciences will not provide any technological, educational or informational support in connection with the use of this code and data.

##Warning.## By receiving this code and data, user accepts these terms, and uses the code and data, solely at its own risk.
========================================================================
"""
# In[1]:


import sys


# In[2]:


for i, p in enumerate(sys.path):
    sys.path[i] = sys.path[i].replace("/software/anaconda/3/", "/MY/PATH/.conda/envs/myenv/")
sys.prefix = '/MY/PATH/.conda/envs/myenv/'


# In[3]:


import os
import tqdm
import pandas as pd
import numpy as np
import utilities as util
import warnings
import pickle
# warnings.filterwarnings('ignore')

import matplotlib.pyplot as plt
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split, GroupShuffleSplit
from sklearn.linear_model import Ridge, LogisticRegression
from sklearn.metrics import (mean_squared_error,
                             classification_report, accuracy_score,
                            plot_confusion_matrix, confusion_matrix, 
                            plot_roc_curve, roc_auc_score, roc_curve, 
                            average_precision_score, plot_precision_recall_curve, precision_recall_curve)
from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier
from sklearn.neural_network import MLPRegressor, MLPClassifier
from sklearn.multioutput import MultiOutputRegressor, MultiOutputClassifier
from sklearn.calibration import CalibratedClassifierCV, calibration_curve
from xgboost import XGBRegressor, XGBClassifier

from bayes_opt import BayesianOptimization

import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.utils.data as Data
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence


# # More Preprocessing

# In[4]:


df = util.read_partially_reviewed_csv()
df = util.get_included_regimen(df)
cycle_lengths = df['cycle_length'].to_dict()
del df


# In[5]:


extra_features = pd.read_csv('data/chemo_processed2.csv')
esas_ecog_features = extra_features[['ecog_grade', 'Wellbeing','Tiredness', 'Pain', 'Shortness of Breath', 'Drowsiness', 
                                     'Lack of Appetite', 'Depression', 'Anxiety', 'Nausea']]
cols = extra_features.columns
blood_work_cols = cols[cols.str.contains('prev')]
blood_work_cols = blood_work_cols.drop('prev_visit')
blood_work_features = extra_features[blood_work_cols]


# In[6]:


blood_types = ['neutrophil', 'hemoglobin', 'platelet']


# In[7]:


def read_data(blood_type):
    df = pd.read_csv(f'data/{blood_type}.csv', dtype={'curr_morph_cd': str, 'curr_topog_cd': str})
    
    # include the new blood work and questionnaire data features
    df = pd.concat([df, esas_ecog_features], axis=1)
    df = pd.concat([df, blood_work_features], axis=1)

    # turn string of numbers columns into integer column 
    df = df.rename({str(i): i for i in range(-5, 29)}, axis='columns')
    
    keep_indices = []
    for regimen, group in df.groupby('regimen'):
        # set blood count measures after a regiment's respective cycle length to null
        cycle_length = int(cycle_lengths[regimen])
        df.loc[group.index, range(cycle_length+1, 29)] = np.nan

        # remove rows that has no blood count measure near the cycle length (within 3 day before administration day)
        if cycle_length == 28:
            cycle_length_window = range(cycle_length-2, cycle_length+1)
        else:  
            cycle_length_window = range(cycle_length-1,cycle_length+2)
        mask = (~group[cycle_length_window].isnull()).sum(axis=1) >= 1
        keep_indices += group[mask].index.tolist()
    df = df.loc[keep_indices]

    # only keep rows that have at least 2 blood count measures
    df = df[(~df[range(-5,29)].isnull()).sum(axis=1) >= 2]
    
    return df

def get_data():
    data = {blood_type: read_data(blood_type) for blood_type in blood_types}
    
    # keep only rows where all blood types are present
    n_indices = data['neutrophil'].index
    h_indices = data['hemoglobin'].index
    p_indices = data['platelet'].index
    keep_indices = n_indices[n_indices.isin(h_indices) & n_indices.isin(p_indices)]
    data = {blood_type: data[blood_type].loc[keep_indices] for blood_type in blood_types}
    return data

def organize_data(data):
    # organize data for model input and target labels
    """
    NBC - neutrophil blood count
    HBC - hemoglobin blood count
    PBC - platelet blood count

    input:                               -->        MODEL         -->            output:
    regimen                                                                      last observed NBC value
    prev observed NBC value                                                      last observed HBC value
    prev observed HBC value                                                      last observed PBC value
    prev observed PBC value
    days since prev observed NBC/HBC/PBC value
    chemo cycle
    immediate new regimen
    intent of systemic treatment
    line of therapy
    lhin cd
    curr morth cd
    curr topog cd
    age 
    sex
    body surface area
    esas/ecog features
    prev observed blood work
    days since prev observed blood work
    

    the last observed value ideally represents the blood count value right before the next chemo regimen
    """
    drop_columns = ['visit_date', 'prev_visit', 'chemo_interval'] + list(range(-5,29))
    model_data = data['neutrophil'].drop(columns=drop_columns) # all blood types have the same values
    model_data = model_data.reset_index(drop=True) # make concatting new columns easier
    
    get_num_days_between_mes = lambda row: np.diff(np.where(~np.isnan(row))[0][-2:])

    for blood_type, df in data.items():
        values = df[range(-5,29)].values
        # get number of days between the last and the previous blood count measurement (for a single row)
        days_in_between = np.array([get_num_days_between_mes(row) for row in values])
        # get all non nan values from each row
        values = [row[~np.isnan(row)] for row in values]
        # keep only the last two values (the prev blood count mes and last blood count mes)
        values = np.array([row[-2:] for row in values])
        # combine the results
        values = np.concatenate((values, days_in_between), axis=1)
        tmp_df = pd.DataFrame(values, columns=[f'prev_{blood_type}_value', f'last_{blood_type}_value', 
                                               f'num_days_btwn_prev_{blood_type}_value'])
        model_data = pd.concat([model_data, tmp_df], axis=1)
        
    return model_data


# In[22]:


data = get_data()
model_data = organize_data(data)


# In[23]:


# Sanity Check - A unit test to make sure we are only getting blood count measures prior to end of cycle length
for blood_type, df in data.items():
    for regimen, group in df.groupby('regimen'):
        cycle_length = int(cycle_lengths[regimen])
        values = group[range(-5, 29)].values
        indices = [np.where(~np.isnan(row))[0]-5 for row in values]
        indices = np.array([row[-2:] for row in indices])
        assert((indices <= cycle_length).all())


# In[24]:


model_data.head(n=10)


# In[25]:


model_data.columns


# In[28]:


print(f'Size of model_data = {len(model_data)}')
print(f"Number of nans in intent_of_systemic_treatment = {model_data['intent_of_systemic_treatment'].isnull().sum()}")
print(f"Number of nans in line_of_therapy = {model_data['line_of_therapy'].isnull().sum()}") # nominal, categorical col
print(f"Number of nans in lhin_cd = {model_data['lhin_cd'].isnull().sum()}")
print(f"Number of nans in curr_morph_cd = {model_data['curr_morph_cd'].isnull().sum()}")
print(f"Number of nans in curr_topog_cd = {model_data['curr_topog_cd'].isnull().sum()}")
print(f"Number of nans in sex = {model_data['sex'].isnull().sum()}")
print(f"Number of nans in body_surface_area = {model_data['body_surface_area'].isnull().sum()}") # ordinal, numeric col
for col in blood_work_cols:
    if 'days_since' in col: continue
    print(f"Number of nans in {col} = {model_data[col].isnull().sum()}")
print("Distribution of regimens\n")
print(model_data['regimen'].value_counts())


# In[29]:


# analyze the correlations
cols = ['prev_neutrophil_value', 'last_neutrophil_value', 
        'prev_hemoglobin_value', 'last_hemoglobin_value', 
        'prev_platelet_value', 'last_platelet_value']
model_data[cols].corr().style.background_gradient(cmap='Greens')


# In[30]:


# analyze the distribution

# the min/max from ReferenceRanges column
# blood_ranges = util.get_blood_ranges()
# blood_ranges = {'platelet': [xxx.x, xxx.x], 'neutrophil': [x.x, xx.x], 'hemoglobin': [xx.x, xxx.x]}
blood_ranges = {'platelet': [0.0, 600.0], 'neutrophil': [0.0, 26.0], 'hemoglobin': [0.0, 256.0]}

def blood_count_value_distribution(model_data, bins=[50, 30, 60]):
    fig = plt.figure(figsize=(20,5))
    for idx, blood_type in enumerate(blood_types):
        min_range, max_range = blood_ranges[blood_type]
        blood_counts = np.clip(model_data[f'prev_{blood_type}_value'], min_range, max_range) # remove/clip the outliers
        ax = fig.add_subplot(1,3,idx+1)
        plt.hist(blood_counts, bins=bins[idx])
        plt.xlabel('Blood Count Value')
        plt.title(blood_type)
    plt.show()
blood_count_value_distribution(model_data)


# In[8]:


def remove_outliers(data):
    """
    Remove the upper and lower 1 percentiles for the columns indicated below
    """
    cols = ['prev_neutrophil_value', 'last_neutrophil_value', 
            'prev_hemoglobin_value', 'last_hemoglobin_value', 
            'prev_platelet_value', 'last_platelet_value']
    num_rows_removed = 0
    for col in cols:
        size = len(data)
        percentile1 = data[col].quantile(0.01)
        percentile99 = data[col].quantile(0.99)
        data = data[(data[col] > percentile1) & (data[col] < percentile99)]
        # print(f'Removed outliers from column {col}, {size-len(data)} rows removed')
        num_rows_removed += size-len(data)
    print('Total number of outlier rows removed =', num_rows_removed)
    return data  

def dummify_data(data):
    # make categorical columns into one-hot encoding
    data['line_of_therapy'] = data['line_of_therapy'].astype('category')
    return pd.get_dummies(data)

def replace_missing_body_surface_area(data, means_train=None):
    # replace missing body surface area with the mean based on sex
    bsa = 'body_surface_area'
    means = {'female': data.loc[data['sex_F'] == 1, bsa].mean(),
             'male': data.loc[data['sex_M'] == 1, bsa].mean()} if means_train is None else means_train
    data.loc[data['sex_F'] == 1, bsa] = data.loc[data['sex_F'] == 1, bsa].fillna(means['female'])
    data.loc[data['sex_M'] == 1, bsa] = data.loc[data['sex_M'] == 1, bsa].fillna(means['male'])
    if means_train is None:
        return data, means
    else:
        return data
    
def replace_missing_blood_work(data, means_train=None):
    # mean impute missing blood work data
    means = data[blood_work_cols].mean() if means_train is None else means_train
    for col in blood_work_cols:
        data[col] = data[col].fillna(means[col])
    if means_train is None:
        return data, means
    else:
        return data
    
def split_data(data):
    """
    Split data into training, validation and test sets based on patient ids
    """
    # convert dtype object to float
    data = data.astype(float)
    
    # create training set
    gss = GroupShuffleSplit(n_splits=1, test_size=0.4, random_state=42)
    train_idxs, test_idxs = next(gss.split(data, groups=data['ikn']))
    train_data = data.iloc[train_idxs]
    test_data = data.iloc[test_idxs]

    # crate validation and testing set
    gss = GroupShuffleSplit(n_splits=1, test_size=0.5, random_state=42)
    valid_idxs, test_idxs = next(gss.split(test_data, groups=test_data['ikn']))

    valid_data = test_data.iloc[valid_idxs]
    test_data = test_data.iloc[test_idxs]

    # sanity check - make sure there are no overlap of patients in the splits
    assert(sum(valid_data['ikn'].isin(set(train_data['ikn']))) + sum(valid_data['ikn'].isin(set(test_data['ikn']))) + 
           sum(train_data['ikn'].isin(set(valid_data['ikn']))) + sum(train_data['ikn'].isin(set(test_data['ikn']))) + 
           sum(test_data['ikn'].isin(set(train_data['ikn']))) + sum(test_data['ikn'].isin(set(valid_data['ikn']))) 
           == 0)
    print(f'Size of splits: Train:{len(train_data)}, Val:{len(valid_data)}, Test:{len(test_data)}')
    print(f"Number of patients: Train:{len(set(train_data['ikn']))}, Val:{len(set(valid_data['ikn']))}, Test:{len(set(test_data['ikn']))}")
    
    # replace missing body surface area with the mean
    train_data, means_train = replace_missing_body_surface_area(train_data.copy())
    print(f"Body Surface Area Mean - Female:{means_train['female']}, Male:{means_train['male']}")
    valid_data = replace_missing_body_surface_area(valid_data.copy(), means_train)
    test_data = replace_missing_body_surface_area(test_data.copy(), means_train)
    
    # mean impute the blood work data
    train_data, means_train = replace_missing_blood_work(train_data.copy())
    valid_data = replace_missing_blood_work(valid_data.copy(), means_train)
    test_data = replace_missing_blood_work(test_data.copy(), means_train)
    
    # normalize the splits based on training data
    train_data, minmax_train = normalize_data(train_data.copy())
    valid_data, minmax_valid = normalize_data(valid_data.copy(), minmax_train)
    test_data, minmax_test = normalize_data(test_data.copy(), minmax_train)
    
    # split into input features and target labels
    cols = data.columns
    feature_cols = cols[~cols.str.contains('last')]
    feature_cols = feature_cols.drop('ikn')
    target_cols = cols[cols.str.contains('last')]
    X_train, X_valid, X_test = train_data[feature_cols], valid_data[feature_cols], test_data[feature_cols]
    Y_train, Y_valid, Y_test = train_data[target_cols], valid_data[target_cols], test_data[target_cols]
    
    return [(X_train, Y_train, minmax_train), (X_valid, Y_valid, minmax_valid), (X_test, Y_test, minmax_test)]

def standardize_data(data):
    scalers = {}
    for blood_type in blood_types:
        cols = [f'prev_{blood_type}_value', f'last_{blood_type}_value']
        scaler = StandardScaler().fit(data[cols])
        scalers[blood_type] = scaler # save for future use
        data[cols] = scaler.transform(data[cols])
    return data, scalers

def destandardize_data(scalers, data):
    for blood_type in blood_types:
        cols = [f'prev_{blood_type}_value', f'last_{blood_type}_value']
        scaler = scalers[blood_type]
        data[cols] = scaler.inverse_transform(data[cols])
    return data

def normalize_data(data, minmax_train=None):
    minmax = pd.DataFrame(index=['min', 'max'])
    
    cols = ['chemo_cycle', 'age', 'body_surface_area'] + esas_ecog_features.columns.tolist() + blood_work_cols.tolist() +            [f'num_days_btwn_prev_{blood_type}_value' for blood_type in blood_types]
    for col in cols:
        tmp = data[col]
        minmax[col] = [tmp.min(), tmp.max()]
        maximum = minmax.loc['max', col] if minmax_train is None else minmax_train.loc['max', col]
        minimum = minmax.loc['min', col] if minmax_train is None else minmax_train.loc['min', col]
        data[col] = (tmp-minimum) / (maximum-minimum)
    
    for blood_type in blood_types:
        cols = [f'prev_{blood_type}_value', f'last_{blood_type}_value']
        tmp = data[cols]
        minmax[blood_type] = [tmp.min().min(), tmp.max().max()]
        maximum = minmax.loc['max', blood_type] if minmax_train is None else minmax_train.loc['max', blood_type]
        minimum = minmax.loc['min', blood_type] if minmax_train is None else minmax_train.loc['min', blood_type]
        data[cols] = (tmp-minimum) / (maximum-minimum)
    
    return data, minmax

def denormalize_data(data, denorm_key):
    """
    data includes feature and target labels as one dataframe
    """
    cols = ['chemo_cycle', 'age', 'body_surface_area'] + esas_ecog_features.columns.tolist() + blood_Work_cols.tolist() +            [f'num_days_btwn_prev_{blood_type}_value' for blood_type in blood_types]
    for col in cols:
        tmp = data[col]
        scale = denorm_key[col]
        data[col] = tmp*(scale.max() - scale.min()) + scale.min()
    
    for blood_type in blood_types:
        cols = [f'prev_{blood_type}_value', f'last_{blood_type}_value']
        tmp = data[cols]
        scale = denorm_key[blood_type]
        data[cols] = tmp*(scale.max() - scale.min()) + scale.min()
    
    return data


# In[9]:


data = get_data()
model_data = organize_data(data)
print(f'Size of model_data: {model_data.shape}\nNumber of unique patients: {len(set(model_data.ikn))}')


# In[10]:


model_data = remove_outliers(model_data)
print(f'Size of model_data: {model_data.shape}\nNumber of unique patients: {len(set(model_data.ikn))}')


# In[11]:


model_data = dummify_data(model_data)
print(f'Size of model_data: {model_data.shape}\nNumber of unique patients: {len(set(model_data.ikn))}')


# In[12]:


train, valid, test = split_data(model_data)


# # Model Training - Classification

# In[13]:


X_train, Y_train, minmax_train = train
X_valid, Y_valid, minmax_valid = valid
X_test, Y_test, minmax_test = test


# In[14]:


n_min, n_max = minmax_train['neutrophil']
h_min, h_max = minmax_train['hemoglobin']
p_min, p_max = minmax_train['platelet']
neutrophil_threshold = (1.5 - n_min)/(n_max - n_min)
hemoglobin_threshold = (100 - h_min)/(h_max - h_min)
platelet_threshold = (75 - p_min)/(p_max - p_min)


# In[15]:


def regression_to_classification(target):
    """
    Convert regression labels (last blood count value) to 
    classification labels (if last blood count value is below corresponding threshold)
    """
    target[f'neutrophil < 1.5'] = target['last_neutrophil_value'] < neutrophil_threshold
    target[f'hemoglobin < 100'] = target['last_hemoglobin_value'] < hemoglobin_threshold
    target[f'platelet < 75'] = target['last_platelet_value'] < platelet_threshold
    target = target.drop(columns=[f'last_{blood_type}_value' for blood_type in blood_types])
    return target


# In[16]:


Y_train = regression_to_classification(Y_train)
Y_valid = regression_to_classification(Y_valid)
Y_test = regression_to_classification(Y_test)


# In[17]:


Y_train_distribution = pd.DataFrame([Y_train[col].value_counts() for col in Y_train.columns])
Y_valid_distribution = pd.DataFrame([Y_valid[col].value_counts() for col in Y_valid.columns])
Y_test_distribution = pd.DataFrame([Y_test[col].value_counts() for col in Y_test.columns])
Y_distribution = pd.concat([Y_train_distribution, Y_valid_distribution, Y_test_distribution], axis=1)
cols = pd.MultiIndex.from_product([['Train', 'Valid','Test'], ['False', 'True']])
Y_distribution.columns = cols
Y_distribution.to_csv('models/classification_label_distribution_before_balancing.csv')
Y_distribution


# In[18]:


# upsample the data by increasing platelet < 75 by 10 folds
indices = Y_train.index.tolist() + Y_train[Y_train['platelet < 75']].index.tolist()*9
Y_train = Y_train.loc[indices]
X_train = X_train.loc[indices]
indices = Y_valid.index.tolist() + Y_valid[Y_valid['platelet < 75']].index.tolist()*9
Y_valid = Y_valid.loc[indices]
X_valid = X_valid.loc[indices]


# In[19]:


Y_train_distribution = pd.DataFrame([Y_train[col].value_counts() for col in Y_train.columns])
Y_valid_distribution = pd.DataFrame([Y_valid[col].value_counts() for col in Y_valid.columns])
Y_test_distribution = pd.DataFrame([Y_test[col].value_counts() for col in Y_test.columns])
Y_distribution = pd.concat([Y_train_distribution, Y_valid_distribution, Y_test_distribution], axis=1)
cols = pd.MultiIndex.from_product([['Train', 'Valid','Test'], ['False', 'True']])
Y_distribution.columns = cols
Y_distribution.to_csv('models/classification_label_distribution_after_balancing.csv')
Y_distribution


# In[20]:


cols = pd.MultiIndex.from_product([['Train', 'Valid'], blood_types])
indices = pd.MultiIndex.from_product([[], []])
score_df = pd.DataFrame(index=indices, columns=cols)


# ### Baseline Models - Predict Previous Value

# In[21]:


for metric in ['Acc', 'Precision', 'Recall', 'F1 Score']:
    score_df.loc[('Baseline - Prev', metric), :] = np.nan


# In[22]:


for split, X, Y in [('Train', X_train, Y_train), ('Valid', X_valid, Y_valid), ('Test', X_test, Y_test)]:
    for blood_type in blood_types:
        col = Y.columns[Y.columns.str.contains(blood_type)]
        Y_true = Y[col]
        Y_pred = X[f'prev_{blood_type}_value'] < neutrophil_threshold
        report = classification_report(Y_true, Y_pred, output_dict=True)
        
        score_df.loc[('Baseline - Prev', 'Acc'), (split, blood_type)] = report['accuracy']
        
        # predicted true positive over all predicted positive
        score_df.loc[('Baseline - Prev', 'Precision'), (split, blood_type)] = report['True']['precision']
        
        # predicted true positive over all true positive (aka senstivity)
        score_df.loc[('Baseline - Prev', 'Recall'), (split, blood_type)] = report['True']['recall']
        
        # 2*precision*recall / (precision + recall)
        score_df.loc[('Baseline - Prev', 'F1 Score'), (split, blood_type)] = report['True']['f1-score']


# In[23]:


score_df


# ### Machine Learning Models

# In[24]:


ml_models = {"LR": LogisticRegression, # L2 Regularized Logistic Regression
             "XGB": XGBClassifier, # Extreme Gradient Boostring
             "RF": RandomForestClassifier,
             "NN": MLPClassifier} # Multilayer perceptron (aka neural network)


# In[26]:


# Test speed of training
params = {'max_iter': 1000}
calib_param_logistic = {'method': 'sigmoid', 'cv': 3}
model = LogisticRegression(**params)
model = MultiOutputClassifier(CalibratedClassifierCV(model, **calib_param_logistic))
for i in tqdm.tqdm(range(1)):
    model.fit(X_train, Y_train)


# In[42]:


calib_param = {'method': 'isotonic', 'cv': 3}
calib_param_logistic = {'method': 'sigmoid', 'cv': 3}

def evaluate(model, eval_NN=False):
    model.fit(X_train, Y_train)
    pred_prob = model.predict_proba(X_valid)
    result = []
    for i, blood_type in enumerate(blood_types):
        col = Y_valid.columns[Y_valid.columns.str.contains(blood_type)]
        Y_true = Y_valid[col]
        Y_pred_prob = pred_prob[:, i] if eval_NN else pred_prob[i][:, 1]
        result.append(average_precision_score(Y_true, Y_pred_prob))
    return np.mean(result)

def lr_evaluate(C):
    params = {'C': C, 
              'class_weight': 'balanced',
              'max_iter': 1000,
              'random_state': 42}
    model = MultiOutputClassifier(CalibratedClassifierCV(ml_models['LR'](**params), **calib_param_logistic))
    return evaluate(model)

# weight for positive examples to account for imbalanced dataset
# scale_pos_weight = [neg_count/pos_count for index, (neg_count, pos_count) in Y_distribution['Train'].iterrows()]
# min_child_weight = max(scale_pos_weight) * 6 # can't have less than 6 samples in a leaf node
def xgb_evaluate(learning_rate, n_estimators, max_depth, gamma, reg_lambda):
    params = {'learning_rate': learning_rate, 
              'n_estimators': int(n_estimators), 
              'max_depth': int(max_depth),
              'gamma': gamma, 
              'reg_lambda': reg_lambda,
              # 'scale_pos_weight': scale_pos_weight,
              # 'min_child_weight': min_child_weight, # set to 6 if not using scale_pos_weight
              'min_child_weight': 6,
              'random_state': 42,
              'n_jobs': min(os.cpu_count(), 32),
             }
    model = MultiOutputClassifier(CalibratedClassifierCV(ml_models['XGB'](**params), **calib_param))
    return evaluate(model)

def rf_evaluate(n_estimators, max_depth, max_features):
    params = {'n_estimators': int(n_estimators),
              'max_depth': int(max_depth),
              'max_features': max_features,
              'min_samples_leaf': 6, # can't allow leaf node to have less than 6 samples
              'class_weight': 'balanced_subsample',
              'random_state': 42,
              'n_jobs': min(os.cpu_count(), 32)}
    model = MultiOutputClassifier(CalibratedClassifierCV(ml_models['RF'](**params), **calib_param))
    return evaluate(model)

def nn_evaluate(learning_rate_init, batch_size, momentum, alpha, 
                first_layer_size, second_layer_size, third_layer_size):
    params = {'learning_rate_init': learning_rate_init,
              'batch_size': int(batch_size),
              'momentum': momentum,
              'alpha': alpha,
              'hidden_layer_sizes': (int(first_layer_size), int(second_layer_size), int(third_layer_size)),
              'max_iter': 100,
              'random_state': 42}
    model = CalibratedClassifierCV(ml_models['NN'](**params), **calib_param)
    return evaluate(model, eval_NN=True)

model_tuning_config = {'LR': (lr_evaluate, {'init_points': 3, 'n_iter': 10}, {'C': (0, 1)}),
                       'XGB': (xgb_evaluate, {'init_points': 5, 'n_iter': 25}, {'learning_rate': (0.001, 0.1),
                                                                                'n_estimators': (50, 200),
                                                                                'max_depth': (3, 7),
                                                                                'gamma': (0, 1),
                                                                                'reg_lambda': (0, 1)}),
                       'RF': (rf_evaluate, {'init_points': 3, 'n_iter': 20}, {'n_estimators': (50, 200),
                                                                              'max_depth': (3, 7),
                                                                              'max_features': (0.01, 1)}),
                       'NN': (nn_evaluate, {'init_points': 5, 'n_iter': 50}, {'learning_rate_init': (0.001, 0.1),
                                                                              'batch_size': (64, 512),
                                                                              'momentum': (0,1),
                                                                              'alpha': (0,1),
                                                                              'first_layer_size': (64, 256),
                                                                              'second_layer_size': (64, 256),
                                                                              'third_layer_size': (64, 256)})}


# In[43]:


def convert_some_params_to_int(best_param):
    for param in ['max_depth', 'batch_size', 'n_estimators',
                  'first_layer_size', 'second_layer_size', 'third_layer_size']:
        if param in best_param:
            best_param[param] = int(best_param[param])
    return best_param

def train_model_with_best_param(algorithm, model, best_param):
    if algorithm in ['XGB', 'RF']:
        model = MultiOutputClassifier(model(**best_param))
    elif algorithm == 'NN':
        if not 'hidden_layer_sizes' in best_param:
            best_param['hidden_layer_sizes'] = (best_param['first_layer_size'], 
                                                best_param['second_layer_size'], 
                                                best_param['third_layer_size'])
            del best_param['first_layer_size'], best_param['second_layer_size'], best_param['third_layer_size']
        model = model(**best_param)
    elif algorithm == 'LR':
        model = MultiOutputClassifier(model(max_iter=1000, **best_param))
    model.fit(X_train, Y_train)
    return model


# In[ ]:


# Train the models
for algorithm, model in ml_models.items():
    if algorithm in ['LR', 'XGB']: continue # put the algorithms already trained and tuned in this list
        
    # Conduct Bayesian Optimization
    evaluate_function, optim_config, hyperparam_config = model_tuning_config[algorithm]
    bo = BayesianOptimization(evaluate_function, hyperparam_config)
    bo.maximize(acq='ei', **optim_config)
    best_param = bo.max['params']
    best_param = convert_some_params_to_int(best_param)
    print(f'Finished finding best hyperparameters for {algorithm}')
    
    # Save the best hyperparameters
    param_filename = f'models/{algorithm}_classifier_best_param.pkl'
    with open(param_filename, 'wb') as file:    
        pickle.dump(best_param, file)


# In[125]:


# Evaluate the best models
for algorithm, model in ml_models.items():
    for metric in ['Acc', 'Precision', 'Recall', 'F1 Score', 'ROC AUC Score', 'AP Score']:
        score_df.loc[(algorithm, metric), :] = np.nan
    
    # Load best models
    """
    filename = f'models/{algorithm}_classifier.pkl'
    with open(filename, 'rb') as file:
        model = pickle.load(file)
    """

    
    # Load best params
    filename = f'models/{algorithm}_classifier_best_param.pkl'
    with open(filename, 'rb') as file:
        best_param = pickle.load(file)
    model = train_model_with_best_param(algorithm, model, best_param)
    # Save the model
    model_filename = f'models/{algorithm}_classifier.pkl'
    with open(model_filename, 'wb') as file:
        pickle.dump(model, file)
        
    # Evaluate the model
    for split, X, Y in [('Train', X_train, Y_train), ('Valid', X_valid, Y_valid), ('Test', X_test, Y_test)]:
        # 3 x n x 2 matrix, first column is prob of false, second column is prob of true
        pred_prob = model.predict_proba(X) 
        for idx, blood_type in enumerate(blood_types):
            col = Y.columns[Y.columns.str.contains(blood_type)]
            Y_true = Y[col]
            Y_pred_prob = pred_prob[:, idx] if algorithm=='NN' else pred_prob[idx][:, 1]
            Y_pred_bool = Y_pred_prob > 0.5
            report = classification_report(Y_true, Y_pred_bool, output_dict=True, zero_division=1)
            score_df.loc[(algorithm, 'Acc'), (split, blood_type)] = report['accuracy']
            score_df.loc[(algorithm, 'Precision'), (split, blood_type)] = report['True']['precision']
            score_df.loc[(algorithm, 'Recall'), (split, blood_type)] = report['True']['recall']
            score_df.loc[(algorithm, 'F1 Score'), (split, blood_type)] = report['True']['f1-score']
            score_df.loc[(algorithm, 'ROC AUC Score'), (split, blood_type)] = roc_auc_score(Y_true, Y_pred_prob)
            """
            Area Under the Curve for Precision-Recall Curve
            - appropriate for imbalanced dataset
            - average precision is used to summarize PR Curve, although not exactly the same as AUC
            """
            score_df.loc[(algorithm, 'AP Score'), (split, blood_type)] = average_precision_score(Y_true, Y_pred_prob)
            
            # confusion matrix
            if split == 'Test':
                cm = confusion_matrix(Y_true, Y_pred_bool)
                cm = pd.DataFrame(cm, columns=['Predicted False', 'Predicted True'], index=['Actual False', 'Actual True'])
                print(f"\n######## {algorithm} - {split} - {blood_type} #########")
                print(cm)


# In[126]:


score_df = pd.DataFrame(score_df.values.astype(float).round(4), index=score_df.index, columns=score_df.columns)
score_df.to_csv('models/classification_results.csv')


# In[127]:


score_df


# In[128]:


score_df.loc[[i for i in score_df.index if 'AUC' in i[1] or 'AP' in i[1]]]


# In[67]:


def plot_PR_curve(algorithm, model, X, Y, ax):
    pred = model.predict_proba(X)
    avg_precision_scores = []
    for i, blood_type in enumerate(blood_types):
        col = Y.columns[Y.columns.str.contains(blood_type)]
        y_true = Y[col]
        y_scores = pred[:, i]
        precision, recall, thresholds = precision_recall_curve(y_true, y_scores)
        avg_precision_scores.append(np.round(average_precision_score(y_true, y_scores), 2))
        ax.plot(precision, recall)
    ax.legend([blood_type + f'(AP = {avg_precision_scores[i]})' 
               for i, blood_type in enumerate(blood_types)], loc='lower left')
    ax.set_xlabel('Recall (Positive label: True)')
    ax.set_ylabel('Precision (Positive label: True)')
    plt.title(algorithm)


# In[68]:


fig = plt.figure(figsize=(12,9))
plt.subplots_adjust(hspace=0.3)
for idx, (algorithm, _) in enumerate(ml_models.items()):
    # Load model
    filename = f'models/{algorithm}_classifier.pkl'
    with open(filename, 'rb') as file:
        model = pickle.load(file)
    
    ax = fig.add_subplot(2, 2, idx+1)
    if algorithm == 'NN':
        plot_PR_curve(algorithm, model, X_test, Y_test, ax)
        continue
    for idx, blood_type in enumerate(blood_types):
        col = Y_valid.columns[Y_valid.columns.str.contains(blood_type)]
        plot_precision_recall_curve(model.estimators_[idx], X_test, Y_test[col], name=blood_type, ax=ax)
        plt.title(algorithm)
plt.savefig('models/pr_curve.jpg')


# In[69]:


def plot_ROC_curve(algorithm, model, X, Y, ax):
    pred = model.predict_proba(X)
    auc_scores = []
    for i, blood_type in enumerate(blood_types):
        col = Y.columns[Y.columns.str.contains(blood_type)]
        y_true = Y[col]
        y_scores = pred[:, i]
        fpr, tpr, thresholds = roc_curve(y_true, y_scores)
        auc_scores.append(np.round(roc_auc_score(y_true, y_scores), 2))
        ax.plot(fpr, tpr)
    ax.legend([blood_type + f'(AUC = {auc_scores[i]})' 
               for i, blood_type in enumerate(blood_types)], loc='lower right')
    ax.set_xlabel('False Positive Rate (Positive label: True)')
    ax.set_ylabel('True Positive Rate (Positive label: True)')
    plt.title(algorithm)


# In[70]:


fig = plt.figure(figsize=(12,9))
plt.subplots_adjust(hspace=0.3)
for idx, (algorithm, _) in enumerate(ml_models.items()):
    # Load model
    filename = f'models/{algorithm}_classifier.pkl'
    with open(filename, 'rb') as file:
        model = pickle.load(file)
    
    ax = fig.add_subplot(2, 2, idx+1)
    if algorithm == 'NN':  
        plot_ROC_curve(algorithm, model, X_test, Y_test, ax)
        continue
    for idx, blood_type in enumerate(blood_types):
        col = Y_test.columns[Y_test.columns.str.contains(blood_type)]
        plot_roc_curve(model.estimators_[idx], X_test, Y_test[col], name=blood_type, ax=ax)
        plt.title(algorithm)
plt.savefig('models/roc_curve.jpg')


# ## Calibration Plots

# In[71]:


fig = plt.figure(figsize=(12,9))
for idx, (algorithm, model) in enumerate(ml_models.items()):
    # Load model
    filename = f'models/{algorithm}_classifier.pkl'
    with open(filename, 'rb') as file:
        model = pickle.load(file)
    
    ax = fig.add_subplot(2, 2, idx+1)
    ax.plot([0,1],[0,1],'k:', label='perfect calibration')
    pred_prob = model.predict_proba(X_train) 
    for i, blood_type in enumerate(blood_types):
        col = Y_train.columns[Y_train.columns.str.contains(blood_type)]
        y_true = Y_train[col]
        y_pred = pred_prob[:, i] if algorithm=='NN' else pred_prob[i][:, 1]
        prob_true, prob_pred = calibration_curve(y_true, y_pred, n_bins=20)
        ax.plot(prob_true, prob_pred, label=blood_type)
    ax.legend()
    plt.title(algorithm)    
plt.savefig('models/calibration_curve.jpg')


# ## XGB most important features

# In[61]:


cols = X_train.columns


# In[48]:


filename = f'models/XGB_classifier.pkl'
with open(filename, 'rb') as file:
    model = pickle.load(file)


# In[64]:


important_variables = {}
for idx, blood_type in enumerate(blood_types):
    feature_importances = model.estimators_[idx].feature_importances_
    important_variables[blood_type] = cols[np.argsort(feature_importances * -1)].tolist()


# In[65]:


important_variables['neutrophil']


# In[66]:


important_variables['hemoglobin']


# In[67]:


important_variables['platelet']

# # Study Population Characteristics

def regression_to_classification(data):
    data[f'neutrophil < 1.5'] = data['last_neutrophil_value'] < 1.5
    data[f'hemoglobin < 100'] = data['last_hemoglobin_value'] < 100
    data[f'platelet < 75'] = data['last_platelet_value'] < 75
    data = data.drop(columns=[f'last_{blood_type}_value' for blood_type in blood_types])
    return data
data = get_data()
model_data = organize_data(data)
model_data = regression_to_classification(model_data)
last_ikn_index = model_data['ikn'].drop_duplicates(keep='last').index
# total 
total = len(last_ikn_index)
print(f'Total: {total} (100%)')
# age
age = model_data.loc[last_ikn_index, 'age']
q25, q75 = np.percentile(age, [25, 75])
print(f"Mean age: {np.round(age.mean(),2)}, IQR [{q25}-{q75}]")
# sex
F, M = model_data.loc[last_ikn_index, 'sex'].value_counts()
print(f"Female: {F} ({np.round(F/total, 2)*100}%)")
# baseline labs
count = len(model_data.loc[model_data['platelet < 75'], 'ikn'].unique())
print(f"Platelet < 75 10^9/L: {count} ({np.round(count/total*100, 2)}%)")
count = len(model_data.loc[model_data['neutrophil < 1.5'], 'ikn'].unique())
print(f"Neutrophil < 1.5 10^9/L: {count} ({np.round(count/total*100, 2)}%)")
count = len(model_data.loc[model_data['hemoglobin < 100'], 'ikn'].unique())
print(f"Hemoglobin < 100 g/L: {count} ({np.round(count/total*100, 2)}%)")
get_num_patients = lambda group: len(group['ikn'].unique())
# regimen
ikn_per_regimen_count = model_data.groupby('regimen').apply(get_num_patients)
top10_regimens = ikn_per_regimen_count.sort_values(ascending=False)[0:10]
for regimen, count in top10_regimens.iteritems():
    print(f"Regimen {regimen}: {count} ({np.round(count/total*100, 2)}%)")
# cancer location
mapping = { 'C421': 'Bone Marrow',
            'C209': 'Rectal',
            'C341': 'Bronchus and Lung',
            'C779': 'Lymph Node',
            'C569': 'Ovary',
            'C187': 'Colon',
            'C619': 'Prostate Gland',
            'C504': 'Breast',
            'C180': 'Colon (Cecum)',
            'C541': 'Endocrine'}
ikn_per_cancer_location_count = model_data.groupby('curr_topog_cd').apply(get_num_patients)
top10_cancer_location = ikn_per_cancer_location_count.sort_values(ascending=False)[0:10]
for cancer_location, count in top10_cancer_location.iteritems():
    print(f"Cancer Location {mapping[cancer_location]}: {count} ({np.round(count/total*100, 2)}%)")
# cancer type
mapping = {'81403': 'Adenocarcinoma', # starts at the glands, can happen in many places
           '85003': 'IDC Breast Cancer', # grows in milk duct
           '96803': 'Lymphoma', 
           '97323': 'Multiple Myeloma', # starts in plasma cell
           '84413': 'USC Ovary Cancer',
           '80413': 'Neuroendocrine Carcinoma (Small Cell)',
           '84803': 'Mucinous Carcinoma',
           '83803': '83803',
           '80703': '80703',
           '80103': 'Epithelial Carcinoma',
          }
ikn_per_cancer_type_count = model_data.groupby('curr_morph_cd').apply(get_num_patients)
top10_cancer_type = ikn_per_cancer_type_count.sort_values(ascending=False)[0:10]
for cancer_type, count in top10_cancer_type.iteritems():
    print(f"Cancer Location {mapping[cancer_type]}: {count} ({np.round(count/total*100, 2)}%)")

# # SCRATCH NOTES

# ## Model Training - Regression

# In[31]:


X_train, Y_train, minmax_train = train
X_valid, Y_valid, minmax_valid = valid


# In[32]:


cols = pd.MultiIndex.from_product([['Train', 'Valid'], blood_types])
indices = pd.MultiIndex.from_product([[], []])
score_df = pd.DataFrame(index=indices, columns=cols)


# #### Baseline Models - Predict Previous Value

# In[33]:


score_df.loc[('Baseline - Prev', 'RMSE'), :] = np.nan # Root Mean Squared Error
for split, (X, Y, minmax) in [('Train', train), ('Valid', valid), ('Test', test)]:
    for blood_type in blood_types:
        scale = minmax[blood_type]
        Y_true = Y[f'last_{blood_type}_value']*(scale.max()-scale.min())
        Y_pred = X[f'prev_{blood_type}_value']*(scale.max()-scale.min())
        RMSE = mean_squared_error(Y_true, Y_pred, squared=False)
        score_df.loc[('Baseline - Prev', 'RMSE'), (split, blood_type)] = np.round(RMSE, 2)


# In[34]:


score_df


# #### Baseline Models - Predict Average Value

# In[35]:


score_df.loc[('Baseline - Avg', 'RMSE'), :] = np.nan # Root Mean Squared Error
for split, (X, Y, minmax) in [('Train', train), ('Valid', valid), ('Test', test)]:
    for blood_type in blood_types:
        scale = minmax[blood_type]
        Y_true = Y[f'last_{blood_type}_value']*(scale.max()-scale.min())
        Y_pred = [Y[f'last_{blood_type}_value'].mean()*(scale.max()-scale.min()),]*len(Y)
        RMSE = mean_squared_error(Y_true, Y_pred, squared=False)
        score_df.loc[('Baseline - Avg', 'RMSE'), (split, blood_type)] = np.round(RMSE, 2)


# In[36]:


score_df


# #### Machine Learning Models

# In[37]:


ml_models = {"LR": Ridge, # L2 Regularized Linear Regression
             "XGB": XGBRegressor, # Extreme Gradient Boostring
             "RF": RandomForestRegressor,
             "NN": MLPRegressor} # Multilayer perceptron (aka neural network)


# In[27]:


# test training speed
model = ml_models['NN']
# model = MultiOutputRegressor(model())
model = model()
for _ in tqdm.tqdm(range(1)):
    model.fit(X_train, Y_train)


# In[129]:


def evaluate(model):
    model.fit(X_train, Y_train)
    result = []
    pred = model.predict(X_valid)
    for i, blood_type in enumerate(blood_types):
        Y_true = Y_valid[f'last_{blood_type}_value']
        Y_pred = pred[:, i]
        result.append(-mean_squared_error(Y_true, Y_pred))
    return np.mean(result)

def ridge_evaluate(alpha):
    params = {'alpha': alpha, 
              'random_state': 42}
    model = ml_models['LR'](**params)
    return evaluate(model)

def xgb_evaluate(learning_rate, n_estimators, max_depth, gamma, reg_lambda):
    params = {'learning_rate': learning_rate, 
              'n_estimators': int(n_estimators), 
              'max_depth': int(max_depth),
              'gamma': gamma, 
              'reg_lambda': reg_lambda,
              'random_state': 42,
              'n_jobs': min(os.cpu_count(), 16)}
    model = MultiOutputRegressor(ml_models['XGB'](**params))
    return evaluate(model)

def rf_evaluate(n_estimators, max_depth, max_features):
    params = {'n_estimators': int(n_estimators),
              'max_depth': int(max_depth),
              'max_features': max_features,
              'random_state': 42,
              'n_jobs': min(os.cpu_count(), 16)}
    model = MultiOutputRegressor(ml_models['RF'](**params))
    return evaluate(model)

def nn_evaluate(learning_rate_init, batch_size, momentum, alpha, 
                first_layer_size, second_layer_size, third_layer_size):
    params = {'learning_rate_init': learning_rate_init,
              'batch_size': int(batch_size),
              'momentum': momentum,
              'alpha': alpha,
              'hidden_layer_sizes': (int(first_layer_size), int(second_layer_size), int(third_layer_size)),
              'max_iter': 100,
              'random_state': 42}
    model = ml_models['NN'](**params)
    return evaluate(model)

model_tuning_config = {'LR': (ridge_evaluate, {'init_points': 3, 'n_iter': 5}, {'alpha': (0, 1)}),
                       'XGB': (xgb_evaluate, {'init_points': 5, 'n_iter': 25}, {'learning_rate': (0.001, 0.1),
                                                                                'n_estimators': (50, 200),
                                                                                'max_depth': (3, 7),
                                                                                'gamma': (0, 1),
                                                                                'reg_lambda': (0, 1)}),
                       'RF': (rf_evaluate, {'init_points': 3, 'n_iter': 20}, {'n_estimators': (50, 200),
                                                                              'max_depth': (3, 7),
                                                                              'max_features': (0.0001, 1)}),
                       'NN': (nn_evaluate, {'init_points': 5, 'n_iter': 75}, {'learning_rate_init': (0.001, 0.1),
                                                                              'batch_size': (64, 512),
                                                                              'momentum': (0,1),
                                                                              'alpha': (0,1),
                                                                              'first_layer_size': (64, 256),
                                                                              'second_layer_size': (64, 256),
                                                                              'third_layer_size': (64, 256)})}


# In[20]:


def convert_some_params_to_int(best_param):
    for param in ['max_depth', 'n_estimators','batch_size', 
                  'first_layer_size', 'second_layer_size', 'third_layer_size']:
        if param in best_param:
            best_param[param] = int(best_param[param])
    return best_param

def train_model_with_best_param(algorithm, model, best_param):
    if algorithm in ['XGB', 'RF']:
        model = MultiOutputRegressor(model(**best_param))
    elif algorithm == 'NN':
        if 'hidden_layer_sizes' not in best_param:
            best_param['hidden_layer_sizes'] = (best_param['first_layer_size'], 
                                                best_param['second_layer_size'], 
                                                best_param['third_layer_size'])
            del best_param['first_layer_size'], best_param['second_layer_size'], best_param['third_layer_size']
        model = model(**best_param)
    else:
        model = model(**best_param)
    model.fit(X_train, Y_train)
    return model


# In[ ]:


# Train the models
for algorithm, model in ml_models.items():
    # Conduct Bayesian Optimization
    evaluate_function, optim_config, hyperparam_config = model_tuning_config[algorithm]
    bo = BayesianOptimization(evaluate_function, hyperparam_config)
    bo.maximize(acq='ei', **optim_config)
    best_param = bo.max['params']
    best_param = convert_some_params_to_int(best_param)
    print(f'Finished finding best hyperparameters for {algorithm}')
    
    # Traing model using best param
    model = train_model_with_best_param(algorithm, model, best_param)
    print(f'Finished training {algorithm}')
    
    # Save the best hyperparameters
    param_filename = f'models/{algorithm}_best_param.pkl'
    with open(param_filename, 'wb') as file:    
        pickle.dump(best_param, file)


# In[38]:


# Evaluate the best models
for algorithm, model in ml_models.items():
    score_df.loc[(algorithm, 'RMSE'), :] = np.nan
    
    # Load best models
    filename = f'models/{algorithm}_regressor.pkl'
    with open(filename, 'rb') as file:
        model = pickle.load(file)
    
    # Load best params
    """
    filename = f'models/{algorithm}_best_param.pkl'
    with open(filename, 'rb') as file:
        best_param = pickle.load(file)
    model = train_model_with_best_param(algorithm, model, best_param)
    # Save the model
    model_filename = f'models/{algorithm}_regressor.pkl'
    with open(model_filename, 'wb') as file:
        pickle.dump(model, file)
    """
    
    # Evaluate the model
    for split, (X, Y, minmax) in [('Train', train), ('Valid', valid), ('Test', test)]:
        pred = model.predict(X)
        for i, blood_type in enumerate(blood_types):
            scale = minmax[blood_type]
            Y_true = Y[f'last_{blood_type}_value']*(scale.max()-scale.min())
            Y_pred = pred[:, i]*(scale.max()-scale.min())
            RMSE = mean_squared_error(Y_true, Y_pred, squared=False)
            score_df.loc[(algorithm, 'RMSE'), (split, blood_type)] = np.round(RMSE, 2)


# In[39]:


score_df.to_csv('models/regression_results.csv')


# In[43]:


minmax[['neutrophil', 'hemoglobin', 'platelet']]


# In[41]:


score_df


# ## Display Best PARAMS

# In[11]:


indices = [[], []]
values = []
for algorithm in ['LR', 'RF', 'XGB', 'NN']:
    filename = f'models/{algorithm}_classifier_best_param.pkl'
    with open(filename, 'rb') as file:
        best_param = pickle.load(file)
    for param, value in best_param.items():
        indices[0].append(algorithm)
        indices[1].append(param)
        values.append(value)


# In[13]:


pd.DataFrame(values, index=indices, columns=['Classification'])


# In[14]:


indices = [[], []]
values = []
for algorithm in ['LR', 'RF', 'XGB', 'NN']:
    filename = f'models/{algorithm}_best_param.pkl'
    with open(filename, 'rb') as file:
        best_param = pickle.load(file)
    for param, value in best_param.items():
        indices[0].append(algorithm)
        indices[1].append(param)
        values.append(value)


# In[16]:


pd.DataFrame(values, index=indices, columns=['Regression'])


# ## Results for each Grade

# In[144]:


thresholds = [(1.5, 100, 75), (1.0, 80, 50), (0.5, 80, 25)] # grade1 (neutrophil, hemoglobin, platelet), grade2, grade3


# In[148]:


train, valid, test = split_data(model_data)
    
for neutrophil_threshold, hemoglobin_threshold, platelet_threshold in thresholds:
    X_train, Y_train, minmax_train = train
    X_valid, Y_valid, minmax_valid = valid
    X_test, Y_test, minmax_test = test

    n_min, n_max = minmax_train['neutrophil']
    h_min, h_max = minmax_train['hemoglobin']
    p_min, p_max = minmax_train['platelet']
    neutrophil_threshold = (neutrophil_threshold - n_min)/(n_max - n_min)
    hemoglobin_threshold = (hemoglobin_threshold - h_min)/(h_max - h_min)
    platelet_threshold = (platelet_threshold - p_min)/(p_max - p_min)
    
    def regression_to_classification(target):
        """
        Convert regression labels (last blood count value) to 
        classification labels (if last blood count value is below corresponding threshold)
        """
        target[f'neutrophil < {neutrophil_threshold}'] = target['last_neutrophil_value'] < neutrophil_threshold
        target[f'hemoglobin < {hemoglobin_threshold}'] = target['last_hemoglobin_value'] < hemoglobin_threshold
        target[f'platelet < {platelet_threshold}'] = target['last_platelet_value'] < platelet_threshold
        target = target.drop(columns=[f'last_{blood_type}_value' for blood_type in blood_types])
        return target

    Y_train = regression_to_classification(Y_train.copy())
    Y_valid = regression_to_classification(Y_valid.copy())
    Y_test = regression_to_classification(Y_test.copy())
    
    Y_train_distribution = pd.DataFrame([Y_train[col].value_counts() for col in Y_train.columns])
    Y_valid_distribution = pd.DataFrame([Y_valid[col].value_counts() for col in Y_valid.columns])
    Y_test_distribution = pd.DataFrame([Y_test[col].value_counts() for col in Y_test.columns])
    Y_distribution = pd.concat([Y_train_distribution, Y_valid_distribution, Y_test_distribution], axis=1)
    cols = pd.MultiIndex.from_product([['Train', 'Valid','Test'], ['True', 'False']])
    Y_distribution.columns = cols
    # Y_distribution.to_csv('models/classification_label_distribution.csv', index=False)
    print(Y_distribution)

# WITHOUT FALSE EXAMPLES, RESULTS WILL BE MEANINGLESS


# ### PyTorch Implementation of Simple Neural Network Regressor

# In[73]:


def torchify(data, labels):
    data = torch.Tensor(data.values)
    labels = torch.Tensor(labels.values)
    return Data.TensorDataset(data, labels)


# In[54]:


model = nn.Sequential(
    nn.Linear(X_train.shape[1], 128),
    nn.LeakyReLU(), 
    nn.Linear(128, 64),
    nn.LeakyReLU(), 
    nn.Linear(64, 3))


# In[ ]:


def evaluate(model, loader, criterion):
    total_loss = 0
    for i, (data, labels) in enumerate(loader):
        if torch.cuda.is_available():
            data = data.cuda()
            labels = labels.cuda()
        pred = model(data)
        loss = criterion(pred, labels)
        loss = loss.mean(axis=0)
        total_loss += loss
    return total_loss.detach().numpy() / (i+1)

def train_model(model, save_path, batch_size=512, epochs=80, learning_rate=0.0005, decay=0):
    
    best_val_loss = np.inf
    best_model_param = None
    torch.manual_seed(42)
    
    train_dataset = torchify(X_train, Y_train)
    train_loader = Data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)
    valid_dataset = torchify(X_valid, Y_valid)
    valid_loader = Data.DataLoader(dataset=valid_dataset, batch_size=batch_size, shuffle=True)
    
    criterion = nn.MSELoss(reduction='none')
    optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=decay)
    
    train_losses = np.zeros((epochs, 3))
    valid_losses = np.zeros((epochs, 3))
    counter = 0 # for early stopping
    
    for epoch in range(epochs):
        train_loss = 0
        for i, (data, labels) in enumerate(train_loader):
            if torch.cuda.is_available():
                data = data.cuda()
                labels = labels.cuda()
            pred = model(data)
            loss = criterion(pred, labels)
            
            loss = loss.mean(axis=0)
            train_loss += loss
        
            loss = loss.mean()
            loss.backward() # back propagation, compute gradients
            optimizer.step() # apply gradients
            optimizer.zero_grad() # clear gradients for next train
            
        train_losses[epoch] = train_loss.detach().numpy()/(i+1)
        valid_losses[epoch] = evaluate(model, valid_loader, criterion)
        print(f"Epoch: {epoch+1}, Train Loss: {train_losses[epoch].mean()}, Valid Loss: {valid_losses[epoch].mean()}")
        
        if valid_losses[epoch].mean() < best_val_loss:
            print('Saving Best Model')
            best_val_loss = valid_losses[epoch].mean()
            best_model_param = model.state_dict()
            counter = 0
        
        # early stopping
        if counter > 30: 
            train_losses = train_losses[:epoch+1]
            valid_losses = valid_losses[:epoch+1]
            break
        counter += 1
    
    print(f'Writing best model parameter to {save_path}')
    torch.save(best_model_param, save_path)
            
    return train_losses, valid_losses


# In[25]:


save_path = 'models/basic_nn_regressor'
train_losses, valid_losses = train_model(model, save_path)


# In[26]:


fig = plt.figure(figsize=(15,5))
ax = fig.add_subplot(1, 2, 1)
plt.plot(range(len(train_losses)), train_losses)
plt.title('Training Loss')
plt.legend(blood_types)
ax = fig.add_subplot(1,2, 2)
plt.plot(range(len(valid_losses)), valid_losses)
plt.title('Validation loss')
plt.legend(blood_types)
plt.show()


# In[55]:


# best result
save_path = 'models/basic_nn_regressor'
model.load_state_dict(torch.load(save_path))

score_df.loc[('NN', 'MSE'), :] = np.nan
for split, X, Y in [('Train', X_train, Y_train), ('Valid', X_valid, Y_valid)]:
    pred = model(torch.Tensor(X.values)).detach().numpy()
    for i, blood_type in enumerate(blood_types):
        Y_true = Y[f'last_{blood_type}_value']
        Y_pred = pred[:, i]
        score_df.loc[('NN', 'MSE'), (split, blood_type)] = mean_squared_error(Y_true, Y_pred)


# In[56]:


score_df


# ### PyTorch Implementation of Simple Neural Network Classifier

# In[ ]:


# weight for positive examples to account for imbalanced dataset
ratio = [Y_train[col].value_counts() for col in Y_train.columns]
pos_weight = torch.tensor([neg_count/pos_count for neg_count, pos_count in ratio])


# In[68]:


def torchify(data, labels):
    data = torch.Tensor(data.values)
    labels = torch.Tensor(labels.values)
    return Data.TensorDataset(data, labels)


# In[75]:


# TODO: You can try skip connections, dropout
model = nn.Sequential(
    nn.Linear(X_train.shape[1], 128),
    nn.LeakyReLU(), 
    nn.Linear(128, 64),
    nn.LeakyReLU(), 
    nn.Linear(64, 3),
    nn.Sigmoid())


# In[ ]:


def evaluate(model, loader, criterion):
    total_loss = 0
    total_score = 0
    for i, (data, labels) in enumerate(loader):
        if torch.cuda.is_available():
            data = data.cuda()
            labels = labels.cuda()
        pred = model(data)
        loss = criterion(pred, labels)
        loss = loss.mean(axis=0)
        total_loss += loss

        pred = pred > 0.5
        total_score += np.array([accuracy_score(labels[:, i], pred[:, i]) for i in range(3)])
    return total_loss.detach().numpy() / (i+1), total_score/(i+1)

def train_model(model, save_path, batch_size=512, epochs=80, learning_rate=0.0005, decay=0):
    best_val_loss = np.inf
    best_model_param = None
    torch.manual_seed(42)

    train_dataset = torchify(X_train, Y_train)
    train_loader = Data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)
    valid_dataset = torchify(X_valid, Y_valid)
    valid_loader = Data.DataLoader(dataset=valid_dataset, batch_size=batch_size, shuffle=True)

    criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight, reduction='none')
    optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=decay)

    train_losses = np.zeros((epochs, 3))
    valid_losses = np.zeros((epochs, 3))
    train_scores = np.zeros((epochs, 3)) # acc score
    valid_scores = np.zeros((epochs, 3)) # acc score
    counter = 0 # for early stopping
    
    for epoch in range(epochs):
        train_loss = 0
        train_score = 0
        for i, (data, labels) in enumerate(train_loader):
            if torch.cuda.is_available():
                data = data.cuda()
                labels = labels.cuda()
            pred = model(data)
            loss = criterion(pred, labels)

            loss = loss.mean(axis=0)
            train_loss += loss

            pred = pred > 0.5
            train_score += np.array([accuracy_score(labels[:, i], pred[:, i]) for i in range(3)])

            loss = loss.mean()
            loss.backward() # back propagation, compute gradients
            optimizer.step() # apply gradients
            optimizer.zero_grad() # clear gradients for next train

        train_losses[epoch] = train_loss.detach().numpy()/(i+1)
        train_scores[epoch] = train_score/(i+1)
        valid_losses[epoch], valid_scores[epoch] = evaluate(model, valid_loader, criterion)
        statement = f"Epoch: {epoch+1}, Train Loss: {np.round(train_losses[epoch].mean(),4)}, Valid Loss: {np.round(valid_losses[epoch].mean(),4)}, Train Accuracy: {np.round(train_scores[epoch].mean(), 4)}, Valid Accuracy: {np.round(valid_scores[epoch].mean(),4)}"
        print(statement)
        if valid_losses[epoch].mean() < best_val_loss:
            print('Saving Best Model Parameters')
            best_val_loss = valid_losses[epoch].mean()
            best_model_param = model.state_dict()
            counter = 0
            
        # early stopping
        if counter > 30: 
            train_losses = train_losses[:epoch+1]
            valid_losses = valid_losses[:epoch+1]
            train_scores = train_scores[:epoch+1]
            valid_scores = valid_scores[:epoch+1]
            break
        counter += 1
            
    print(f'Writing best model parameter to {save_path}')
    torch.save(best_model_param, save_path)
    
    return train_losses, valid_losses, train_scores, valid_scores


# In[71]:


save_path = 'models/basic_nn_classifier'
train_losses, valid_losses, train_scores, valid_scores = train_model(model, save_path=save_path)


# In[72]:


fig = plt.figure(figsize=(15,10))
ax = fig.add_subplot(2, 2, 1)
plt.plot(range(len(train_losses)), train_losses)
plt.title('Training Loss')
plt.legend(blood_types)
ax = fig.add_subplot(2,2, 2)
plt.plot(range(len(valid_losses)), valid_losses)
plt.title('Validation loss')
plt.legend(blood_types)
ax = fig.add_subplot(2, 2, 3)
plt.plot(range(len(train_scores)), train_scores)
plt.title('Training Accuracy')
plt.legend(blood_types)
ax = fig.add_subplot(2, 2, 4)
plt.plot(range(len(valid_scores)), valid_scores)
plt.title('Validation Accuracy')
plt.legend(blood_types)
plt.show()


# In[76]:


# best result
save_path = 'models/basic_nn_classifier'
model.load_state_dict(torch.load(save_path))
algorithm = 'NN'

for metric in ['Acc', 'Precision', 'Recall', 'F1 Score', 'AUC Score']:
    score_df.loc[(algorithm, metric), :] = np.nan
    
for split, X, Y in [('Train', X_train, Y_train), ('Valid', X_valid, Y_valid)]:
    pred_prob = model(torch.Tensor(X.values)).detach().numpy()
    
    for idx, blood_type in enumerate(blood_types):
        Y_true = Y[col]
        Y_pred_prob = pred_prob[:, idx]
        Y_pred_bool = Y_pred_prob > 0.5
        report = classification_report(Y_true, Y_pred_bool, output_dict=True, zero_division=1)
        
        score_df.loc[(algorithm, 'Acc'), (split, blood_type)] = report['accuracy']
        score_df.loc[(algorithm, 'Precision'), (split, blood_type)] = report['True']['precision']
        score_df.loc[(algorithm, 'Recall'), (split, blood_type)] = report['True']['recall']
        score_df.loc[(algorithm, 'F1 Score'), (split, blood_type)] = report['True']['f1-score']
        score_df.loc[(algorithm, 'AUC Score'), (split, blood_type)] = average_precision_score(Y_true, Y_pred_prob)
        
        # confusion matrix
        if split == 'Valid':
            cm = confusion_matrix(Y_true, Y_pred_bool)
            cm = pd.DataFrame(cm, columns=['Predicted False', 'Predicted True'], index=['Actual False', 'Actual True'])
            print(f"\n############ {split} - {blood_type} #############")
            print(cm)


# In[77]:


score_df


# In[ ]:




